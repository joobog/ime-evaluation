+ /opt/ddn/mvapich/bin/mpiexec -ppn 2 -np 32 -genv MV2_NUM_HCAS 1 -genv MV2_CPU_BINDING_LEVEL core -genv MV2_CPU_BINDING_POLICY scatter --hosts isc17-c01,isc17-c02,isc17-c03,isc17-c04,isc17-c05,isc17-c06,isc17-c07,isc17-c08,isc17-c09,isc17-c11,isc17-c12,isc17-c13,isc17-c14,isc17-c15,isc17-c18,isc17-c22 /esfs/jtacquaviva/software/install/ior/git-ddn/bin/ior -i 3 -s 1 -t 102400 -b 70590136320 -D 120 -a POSIX -F -e -g -z -k -o /esfs/jtacquaviva/ioperf/file_write -w
+ tee -a ./output/COUNT:1#NN:16#PPN:2#API:POSIX#T:102400.txt
IOR-3.0.1: MPI Coordinated Test of Parallel I/O

ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
[cli_7]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 7
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
[cli_6]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 6
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
[cli_4]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 4
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
[cli_0]: ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
[cli_5]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 5
[cli_2]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 2
[cli_12]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 12
[cli_14]: [cli_17]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 17
[cli_8]: [cli_10]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 10
[cli_19]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 19
[cli_20]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 20
[cli_23]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 23
[cli_24]: [cli_28]: [cli_30]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 30
[cli_27]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 27
[cli_1]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 1
[cli_3]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 3
[cli_13]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 13
[cli_15]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 15
[cli_16]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 16
aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 8
[cli_11]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 11
[cli_18]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 18
[cli_21]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 21
[cli_22]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 22
[cli_25]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 25
[cli_29]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 29
[cli_31]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 31
[cli_26]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 26
aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 0
aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 14
[cli_9]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 24
aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 28
aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 9

===================================================================================
=   BAD TERMINATION OF ONE OF YOUR APPLICATION PROCESSES
=   PID 34847 RUNNING AT isc17-c09
=   EXIT CODE: 255
=   CLEANING UP REMAINING PROCESSES
=   YOU CAN IGNORE THE BELOW CLEANUP MESSAGES
===================================================================================
[proxy:0:12@isc17-c14] HYD_pmcd_pmip_control_cmd_cb (pm/pmiserv/pmip_cb.c:912): assert (!closed) failed
[proxy:0:12@isc17-c14] HYDT_dmxu_poll_wait_for_event (tools/demux/demux_poll.c:76): callback returned error status
[proxy:0:12@isc17-c14] main (pm/pmiserv/pmip.c:256): demux engine error waiting for event
[mpiexec@isc17-c04] HYDT_bscu_wait_for_completion (tools/bootstrap/utils/bscu_wait.c:76): one of the processes terminated badly; aborting
[mpiexec@isc17-c04] HYDT_bsci_wait_for_completion (tools/bootstrap/src/bsci_wait.c:23): launcher returned error waiting for completion
[mpiexec@isc17-c04] HYD_pmci_wait_for_completion (pm/pmiserv/pmiserv_pmci.c:218): launcher returned error waiting for completion
[mpiexec@isc17-c04] main (ui/mpich/mpiexec.c:344): process manager error waiting for completion
+ /opt/ddn/mvapich/bin/mpiexec -ppn 2 -np 32 -genv MV2_NUM_HCAS 1 -genv MV2_CPU_BINDING_LEVEL core -genv MV2_CPU_BINDING_POLICY scatter --hosts isc17-c01,isc17-c02,isc17-c03,isc17-c04,isc17-c05,isc17-c06,isc17-c07,isc17-c08,isc17-c09,isc17-c11,isc17-c12,isc17-c13,isc17-c14,isc17-c15,isc17-c18,isc17-c22 /esfs/jtacquaviva/git/ime-evaluation/drop_caches.sh
+ tee -a ./output/COUNT:1#NN:16#PPN:2#API:POSIX#T:102400.txt
+ /opt/ddn/mvapich/bin/mpiexec -ppn 2 -np 32 -genv MV2_NUM_HCAS 1 -genv MV2_CPU_BINDING_LEVEL core -genv MV2_CPU_BINDING_POLICY scatter --hosts isc17-c01,isc17-c02,isc17-c03,isc17-c04,isc17-c05,isc17-c06,isc17-c07,isc17-c08,isc17-c09,isc17-c11,isc17-c12,isc17-c13,isc17-c14,isc17-c15,isc17-c18,isc17-c22 /esfs/jtacquaviva/software/install/ior/git-ddn/bin/ior -i 3 -s 1 -t 102400 -b 70590136320 -D 120 -a POSIX -F -e -g -z -k -o /esfs/jtacquaviva/indread16/file -r
IOR-3.0.1: MPI Coordinated Test of Parallel I/O

ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
[cli_20]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 20
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
[cli_13]: ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
[cli_21]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 21
aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 13
[cli_1]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 1
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
[cli_12]: [cli_0]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 12
aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 0
[cli_17]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 17
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
[cli_16]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 16
[cli_8]: [cli_9]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 9
aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 8
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
[cli_27]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 27
[cli_26]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 26
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
[cli_11]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 11
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
[cli_23]: ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
[cli_10]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 10
aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 23
[cli_24]: [cli_22]: [cli_25]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 25
aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 22
aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 24
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
[cli_4]: ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
[cli_5]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 4
[cli_19]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 19
aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 5
[cli_18]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 18
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
[cli_29]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 29
[cli_28]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 28
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
[cli_15]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 15
[cli_14]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 14
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
ior ERROR: block size must be a multiple of transfer size, errno 0, Success (ior.c:2293)
[cli_31]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 31
ior ERROR: block size must be a multiple of transfer size, errno 2, No such file or directory (ior.c:2293)
[cli_30]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 30
[cli_3]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 3
[cli_2]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 2
[cli_7]: [cli_6]: aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 6
aborting job:
application called MPI_Abort(MPI_COMM_WORLD, -1) - process 7

===================================================================================
=   BAD TERMINATION OF ONE OF YOUR APPLICATION PROCESSES
=   PID 34897 RUNNING AT isc17-c09
=   EXIT CODE: 255
=   CLEANING UP REMAINING PROCESSES
=   YOU CAN IGNORE THE BELOW CLEANUP MESSAGES
===================================================================================
[proxy:0:6@isc17-c07] HYD_pmcd_pmip_control_cmd_cb (pm/pmiserv/pmip_cb.c:912): assert (!closed) failed
[proxy:0:6@isc17-c07] HYDT_dmxu_poll_wait_for_event (tools/demux/demux_poll.c:76): callback returned error status
[proxy:0:6@isc17-c07] main (pm/pmiserv/pmip.c:256): demux engine error waiting for event
[mpiexec@isc17-c04] HYDT_bscu_wait_for_completion (tools/bootstrap/utils/bscu_wait.c:76): one of the processes terminated badly; aborting
[mpiexec@isc17-c04] HYDT_bsci_wait_for_completion (tools/bootstrap/src/bsci_wait.c:23): launcher returned error waiting for completion
[mpiexec@isc17-c04] HYD_pmci_wait_for_completion (pm/pmiserv/pmiserv_pmci.c:218): launcher returned error waiting for completion
[mpiexec@isc17-c04] main (ui/mpich/mpiexec.c:344): process manager error waiting for completion
+ set +x
/esfs/jtacquaviva/ioperf
stripe_count:  32 stripe_size:   1048576 stripe_offset: -1
